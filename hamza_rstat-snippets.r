{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mahmoudhamza/rstat-snippets?scriptVersionId=118916197\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# R snippets\n\n> instead of researching codes that I have previous used in Rstat projects, I am gathering it here for future use. Anyone is also welcome to use code from here. Suggestions are highly appreciated. ","metadata":{}},{"cell_type":"markdown","source":"# Markdown ","metadata":{}},{"cell_type":"markdown","source":"---\ntitle: \"insert title\"\nauthor: \"insert author\"\ndate: \"`r format(Sys.time(), '%d/%m/%Y')`\" # automatically generate the date \noutput:\n  word_document:\n    toc: yes\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE, message = FALSE, comment = NA, warning = FALSE)\n# this chunk is used to silence code, warnings, comments and hash from appearing in output\n```","metadata":{"execution":{"iopub.status.busy":"2023-02-05T03:48:04.674008Z","iopub.execute_input":"2023-02-05T03:48:04.67668Z","iopub.status.idle":"2023-02-05T03:48:04.810334Z"}}},{"cell_type":"markdown","source":"# Cleaning \n\nvar_label(data) <- list(\n  no.of.muscles.involved = \"No. of muscles involved\", \n  duration.by.minutes = \"Duration (mins)\"\n)\n","metadata":{}},{"cell_type":"markdown","source":"# gtsummary \n\n> ## Descriptive \n\ntbl_summary(tbl1_sum, missing = \"no\", by = \"treatment\", type = list(age ~ 'continuous'))  %>% add_n %>% bold_labels() %>% italicize_levels() %>%  add_p() %>% bold_p()%>% gtsummary::as_flex_table() \n","metadata":{}},{"cell_type":"markdown","source":"# flextable\n\n\n> ## basic table \n\n\nrmdtable <- function(df){\n \n  bes <- autofit(theme_vanilla(flextable(df)))\n\nbes <- bg(bes, bg = \"blue\", part = \"header\")\nbes <- color(bes, color = \"white\", part = \"header\")\n\nreturn(bes) \n}\n","metadata":{}},{"cell_type":"markdown","source":"# Visuals  \n\n### sets a fixed size for all plots to follow \n\n```{r knitr::opts_chunk$set(fig.width=35, fig.height=10) }  \n```","metadata":{}},{"cell_type":"markdown","source":"### Correlation ","metadata":{}},{"cell_type":"code","source":"# library(ggcorrplot)\n\n# cor_data <- data %>% \n#   dplyr::select(Age, Level.on.Std.dose, Percentile, TLC_Level,  Bili.Direct_Level, BUN_Level)   # select some columns to apply descriptive statistics \n\n\n# corr <- cor(cor_data, use = \"complete.obs\")  # compute correlation matrix \n\n# ggcorrplot(corr, hc.order = TRUE, type = \"lower\",   # design a pretty looking graph for correlation matrix \n#    lab = TRUE)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-12T05:55:53.327924Z","iopub.execute_input":"2023-02-12T05:55:53.330063Z","iopub.status.idle":"2023-02-12T05:55:53.450554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[![Screenshot-from-2023-02-11-23-55-07.png](https://i.postimg.cc/Y0gDXrmr/Screenshot-from-2023-02-11-23-55-07.png)](https://postimg.cc/wRqkMdVZ)","metadata":{}},{"cell_type":"markdown","source":"### Barchart with labels","metadata":{}},{"cell_type":"code","source":"# ggplot(data=al_frq, aes(x=Allele, y=Percentage, fill= Allele )) +\n#   geom_bar(stat=\"identity\", fill=\"steelblue\")+  # plot a bar chart \n#  theme_minimal()+\n#   labs(caption=\"Allele *3 did not appear in the population \")+\n#   geom_label_repel(label = al_frq$Percentage)+\n#   theme(legend.position = \"none\") ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[![Screenshot-from-2023-02-11-23-57-44.png](https://i.postimg.cc/xd2fg8JC/Screenshot-from-2023-02-11-23-57-44.png)](https://postimg.cc/xX6V10PD)","metadata":{}},{"cell_type":"markdown","source":"### Boxplot with significant levels","metadata":{}},{"cell_type":"code","source":"# library(ggpubr)\n# x2 = 2\n# x5.5 = 5.5\n#  # same as above \n\n# my_comparisons <- list( c(\"*1/*1\", \"*1/*2\"), c(\"*1/*1\", \"*1/*17\"),  c(\"*1/*17\", \"*1/*2\") )\n\n\n# ggplot(data, aes(x=genotype, y=Level.on.Std.dose, fill=genotype)) +\n#   geom_boxplot(notch = F) +\n#   geom_hline(aes(yintercept=2)) +\n#   geom_text(aes(0,2,label = \"Sub TL\", vjust = 3, hjust = -0.5)) +\n#   geom_hline(aes(yintercept=5.5)) +\n#   geom_text(aes(0,5.5,label = \"Supra TL\", vjust = -2, hjust = -0.75)) +\n#   labs(caption=\"Sub TL: Sub-therapeutic level \n#        Supra TL: Supra-therapeutic level\")+\n#   geom_ribbon(aes(ymin=0,ymax=x5.5), fill=\"blue\", alpha=\"0.5\") +\n#   stat_compare_means(label.y = 15, label.x = 2)+\n#   stat_compare_means(comparisons = my_comparisons, label.y = c(11.5, 10.5, 9.5))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[![Screenshot-from-2023-02-12-00-01-45.png](https://i.postimg.cc/zBQ4t2tj/Screenshot-from-2023-02-12-00-01-45.png)](https://postimg.cc/8Jhys4VJ)","metadata":{}},{"cell_type":"markdown","source":"### stacked bar (two categorical columns -- get the counts)) \n\ndata %>% \n  ggplot(aes(x = treatment, ..count..))+\n  geom_bar(aes(fill = sex), position = \"dodge\") +\n  ggtitle(\"Gender vs treatment\")+\n  theme(text = element_text(size=13))\n  \n  [![Screenshot-from-2022-12-03-22-23-08.png](https://i.postimg.cc/kGb2Vdks/Screenshot-from-2022-12-03-22-23-08.png)](https://postimg.cc/dZJsXgQZ)","metadata":{}},{"cell_type":"markdown","source":"### strip plot with customized jitter \n\nlibrary(scales)\n- Change stripchart colors by groups  \n\ndata %>% \n    ggplot(aes(x=treatment, y=vas.scale, color = treatment)) +\n  geom_point(position = position_jitter(w = 0.2, h = 0))+ \n  ggtitle(\"VAS scale vs treatment\")+\n  ylab('Frequency')+ \n  scale_y_continuous(breaks = pretty_breaks())+\n  theme(text = element_text(size=13))\n\n[![Screenshot-from-2022-12-03-22-26-42.png](https://i.postimg.cc/xdTFhpZ2/Screenshot-from-2022-12-03-22-26-42.png)](https://postimg.cc/hX6r7sgy)","metadata":{}},{"cell_type":"markdown","source":"## plot systolic and diastolic pressure differences across treatments \nthe data usally comes with 1 col for systolic and one for diastolic. Thus it requires tidying \n\nlong = data %>%\n  dplyr::select(sys, dias, treatment) %>% \n  gather(bp, value, sys:dias) %>% \n  mutate(bp = recode(bp, `dias` = \"Diastolic\", `sys` = \"Systolic\"))\n\nlong %>% \n  ggplot(aes(treatment, value, color=treatment)) +\n  geom_boxplot(fill='#eeeeee') +\n  facet_grid(~bp) +\n    theme(text = element_text(family = \"serif\", size = 11), legend.position=\"none\") +\n  ylab(\"Blood pressure (mm Hg)\") +\n  ggtitle(\"Basal Blood pressure vs. Treatment\") +\n  theme(text = element_text(size=13))\n  \n  [![Screenshot-from-2022-12-03-22-30-35.png](https://i.postimg.cc/GtrDgVMP/Screenshot-from-2022-12-03-22-30-35.png)](https://postimg.cc/gXSrnSbr)\n","metadata":{}},{"cell_type":"markdown","source":"## raincloud plot \n\nRPubs - Raincloud Plot with ggplot2\nhttps://rpubs.com/rana2hin/raincloud#:~:text=The%20Raincloud%20Plot%20is%20a,indicator%20that%20groups%20may%20exist).","metadata":{}},{"cell_type":"code","source":"library(tidyverse)\nlibrary(tidyquant)\nlibrary(ggdist)\nlibrary(ggthemes)\n\nmpg %>% \n  filter(cyl %in% c(4, 6, 8)) %>% \n  ggplot(aes(x = factor(cyl), y = hwy, fill = factor(cyl))) +\n  \n  # add half-violin from {ggdist} package\n  stat_halfeye(\n    # adjust bandwidth\n    adjust = 0.5,\n    # move to the right\n    justification = -0.2,\n    # remove the slub interval\n    .width = 0,\n    point_colour = NA\n  ) +\n  geom_boxplot(\n    width = 0.12,\n    # removing outliers\n    outlier.color = NA,\n    alpha = 0.5\n  ) +\n  stat_dots(\n    # ploting on left side\n    side = \"left\",\n    # adjusting position\n    justification = 1.1,\n    # adjust grouping (binning) of observations\n    binwidth = 0.25\n  )","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:16.051375Z","iopub.execute_input":"2023-02-05T06:45:16.053268Z","iopub.status.idle":"2023-02-05T06:45:18.671736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Line graph for each level of binary variable ","metadata":{}},{"cell_type":"code","source":"# ggplot(mapping = aes(x = Var1, y = Freq, group =1 )) +\n#   geom_line(data = subset(foo, Var2 == 1), aes(color = \"red\")) +\n#   geom_line(data = subset(foo, Var2 == 0), aes(color = \"blue\"))+\n#   theme_minimal()+\n#   labs(x = \"Days to reach optimum level\", y = \"GVHD frequency\")+\n#   scale_color_discrete(name = \"GVHD\", labels = c(\"No\", \"Yes\"))+\n#   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:23.406359Z","iopub.execute_input":"2023-02-05T06:45:23.408544Z","iopub.status.idle":"2023-02-05T06:45:23.421493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## longitudinal data visualization ","metadata":{}},{"cell_type":"code","source":"# https://stats.idre.ucla.edu/r/faq/how-can-i-visualize-longitudinal-data-in-ggplot2/\n# ggplot(data = subset(lda_data, day_post_BMT <= 7 & day_post_BMT >= 1 & level < 550), aes(x = day_post_BMT, y = level, group = MRN)) +\n# geom_line() + stat_smooth(aes(group = 1)) + stat_summary(aes(group = 1),\n#     geom = \"point\", fun.y = median, shape = 22, size = 2, fill = 'blue') + facet_grid(. ~ rec_gender)+\n#   geom_ribbon(aes(ymin=200, ymax=250), alpha=0.0025, fill = \"green\") \n# The blue points represent the median level at each time point. The blue line connecting the points is a smooth line connecting the median points. The green area represents the desired plasma level. \n\n#   Making better spaghetti (plots): Exploring the individuals in longitudinal data with the brolgar pac - RStudio\n# https://www.rstudio.com/resources/rstudioconf-2020/making-better-spaghetti-plots-exploring-the-individuals-in-longitudinal-data-with-the-brolgar-pac/\n\n# Visualise longitudinal data\n# https://cran.r-project.org/web/packages/lcsm/vignettes/v0-longitudinal-plots.html\n# \n\n# Browse Over Longitudinal Data Graphically and Analytically in R • brolgar\n# https://brolgar.njtierney.com/\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:24.810533Z","iopub.execute_input":"2023-02-05T06:45:24.812445Z","iopub.status.idle":"2023-02-05T06:45:24.827385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ROC ","metadata":{}},{"cell_type":"code","source":"# library(pROC)\n# \n# rocobj <- roc(data$GVHD, as.numeric(data$D....18))\n# \n# g <- ggroc(rocobj)\n# \n# g + theme_minimal() + ggtitle(\"My ROC curve\") + \n#     geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color=\"grey\", linetype=\"dashed\")\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:26.093809Z","iopub.execute_input":"2023-02-05T06:45:26.097261Z","iopub.status.idle":"2023-02-05T06:45:26.114095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# another option for ROC\n\n# pred <- with(data,prediction(data$Age.at.time.of.SCT.,data$dose_bin, label.ordering = c(1, 0)))\n# perf <- performance(pred,\"tpr\", \"fpr\")\n# auc <-performance(pred, measure = \"auc\")@y.values[[1]]\n# rd <- data.frame(x=perf@x.values[[1]],y=perf@y.values[[1]])\n# p <- ggplot(rd,aes(x=x,y=y)) + geom_path(size=1)\n# p <- p + geom_segment(aes(x=0,y=0,xend=1,yend=1),colour=\"black\",linetype= 2)\n# p <- p + geom_text(aes(x=1, y= 0, hjust=1, vjust=0, label=paste(sep = \"\", \"AUC = \",round(auc,3) )),colour=\"black\",size=4)\n# p <- p + scale_x_continuous(name= \"False positive rate\")\n# p <- p + scale_y_continuous(name= \"True positive rate\")\n# p\n# \n# opt.cut = function(perf, pred){\n#   cut.ind = mapply(FUN=function(x, y, p){\n#     d = (x - 0)^2 + (y-1)^2\n#     ind = which(d == min(d))\n#     c(sensitivity = y[[ind]], specificity = 1-x[[ind]],\n#       cutoff = p[[ind]])\n#   }, perf@x.values, perf@y.values, pred@cutoffs)\n# }\n# \n# print(opt.cut(perf, pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:26.599844Z","iopub.execute_input":"2023-02-05T06:45:26.602221Z","iopub.status.idle":"2023-02-05T06:45:26.617943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# here I was trying to detect multiple cut points\n \n# opt_cut <- cutpointr(data, Age.at.time.of.SCT., dose_bin, metric = sum_sens_spec, \n#                      tol_metric = 0.05)\n# \n# opt_cut$optimal_cutpoint\n# opt_cut %>% \n#   select(optimal_cutpoint, sum_sens_spec) %>% \n#   unnest\n# \n# plot(opt_cut)\n# \n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:27.076234Z","iopub.execute_input":"2023-02-05T06:45:27.078118Z","iopub.status.idle":"2023-02-05T06:45:27.093472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# here I tried to figure out the optimal number of cut points. \n\n# optimal.cutpoint<-optimal.cutpoints(X = \"Age.at.time.of.SCT.\", status = \"dose_bin\", tag.healthy = 1, methods = \"CB\", data = data, pop.prev = NULL, ci.fit = TRUE, conf.level = 0.95, trace = FALSE)   # http://smart-statistics.com/handling-roc-curves/\n\n# summary(optimal.cutpoint)\n# \n# plot(optimal.cutpoint)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:27.527051Z","iopub.execute_input":"2023-02-05T06:45:27.528948Z","iopub.status.idle":"2023-02-05T06:45:27.542723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Longitudinal data ","metadata":{}},{"cell_type":"markdown","source":"> ## GEE \n\n mf <- formula(level ~ Recipient.s.Gender. + voriconazole + age_bin + wt..D.2)\n\n geeInd <- geeglm(mf, id= Recipient.s.MRN., data=long_data, family=gaussian, corstr=\"ind\")\n\n geeInd_sum <- summary(geeInd)\n \n anova(geeInd)\n\ngee_df <- tidy(geeInd, conf.int = TRUE)\n\ngee_df <- gee_df[2:nrow(gee_df), c(1,2,5:7)]\n\ngee_df$term <- c(\"Gender - Male\", \"voriconazole prescribed\", \"Age (>9)\", \"Weight\")\n\ngee_df <- gee_df %>% \n  mutate(across(where(is.numeric), round, 2))\n\nrmdtbl(gee_df)\n\npop_mean <- tidy(emmeans(geeInd, ~ voriconazole + age_bin))\n\npop_mean <- pop_mean[, c(1,2,3)]\n\nnames(pop_mean) <- c(\"voriconazole\", \"Age\",\"Average plasma level\")\n\nrmdtbl(pop_mean)\n\nplot(emmeans(geeInd, ~voriconazole + age_bin), horizontal=F, ylab=\"Estimated mean\", las = 1)  \n\nThat's population average according to predictors\n\n\n\nBroken Stick Model for Irregular Longitudinal Data\nhttps://cran.r-project.org/web/packages/brokenstick/vignettes/brokenstick-article.html \n ","metadata":{"execution":{"iopub.status.busy":"2023-02-05T05:23:25.655337Z","iopub.execute_input":"2023-02-05T05:23:25.657285Z","iopub.status.idle":"2023-02-05T05:23:25.674146Z"}}},{"cell_type":"markdown","source":"# Models\n\n> ## Multonomial logistic regression \n\nWe chose the multinom function because it does not require the data to be reshaped (as the mlogit package does)\n","metadata":{}},{"cell_type":"code","source":"# multinom(op_dose ~ voriconazole + rec_gender + age_bin +srcr.D.2 + wt..D.2, data = data) %>%\n#   tbl_regression(exponentiate = T) %>%\n#   modify_header(estimate ~ \"**OR**\")\n\n# Model diagnostics\n\n#log_model <- multinom(op_dose ~ voriconazole + Recipient.s.Gender. + age_code, data = data)\n\n#log_model2 <- multinom(op_dose ~ voriconazole + Recipient.s.Gender. , data = data)\n\n#log_model3 <- multinom(op_dose ~ voriconazole  , data = data)\n\n#log_model4 <- multinom(op_dose ~ 1  , data = data)\n\n\n# kable(glance(log_model4), digits = 3)\n# \n# kable(glance(log_model3), digits = 3)\n# \n# kable(glance(log_model2), digits = 3)\n# \n# kable(glance(log_model), digits = 3)\n\n\n#  https://data.princeton.edu/wws509/r/c6s2 \n\n# I was trying to figure out how to test for the model diagnostics, but the model in this link, had predictor variables that failed to fit, so I got confused \n# remember to go back to the previous page in the data frame to get the data they are working with\n\n# x2 <- deviance(log_model2) - deviance(log_model)\n\n#pchisq(x2, 10, lower.tail=FALSE)\n\n# Deviance and AIC improve greatly with addition of each variable. \n# The sequence of addition is : null model, voriconazole, gender then age\n\n# Testing for IIA with the Hausman-McFadden Test\n\n#library(mlogit)\n\n# https://cran.r-project.org/web/packages/mlogit/vignettes/mlogit.pdf \n\n# preparing the data ( changing from wide to long)\n\n# Fish <- mlogit.data(Fishing, shape=\"wide\", varying=2:9, choice=\"mode\")\n# we don't have varying here since simply no variables depend on the op_dose \n\n#dta <- mlogit.data(data, shape = \"wide\", choice = \"op_dose\")\n\n#head(index(dta)) # this reveals a unique ID and the choice \n\n# mod.1 <-mlogit(op_dose ~ 1|  voriconazole + Recipient.s.Gender. + age_code , reflevel = \"less than or equal 1.5\",   data=dta)  \n# #summary(mod.1)\n#  \n# mod.alt1 <- mlogit(op_dose ~ 1|  voriconazole + Recipient.s.Gender. + age_code , reflevel = \"less than or equal 1.5\",   data=dta, alt.subset = c(\"less than or equal 1.5\",\"from 1.51 to 2\"))\n# \n# mod.alt2 <- mlogit(op_dose ~ 1|  voriconazole + Recipient.s.Gender. + age_code , reflevel = \"less than or equal 1.5\",   data=dta, alt.subset = c(\"less than or equal 1.5\",\"more than 2\"))\n# \n# mod.alt3 <- mlogit(op_dose ~ 1|  voriconazole + Recipient.s.Gender. + age_code , reflevel = \"less than or equal 1.5\",   data=dta, alt.subset = c(\"from 1.51 to 2\",\"more than 2\"))\n\n#hmftest(mod.1, mod.alt1)\n#hmftest(mod.1, mod.alt2)\n#hmftest(mod.1, mod.alt3)\n\n# Multinomial logit models are valid under the Independence of Irrelevant Alternatives (IIA)\n# assumption that states that characteristics of one particular choice alternative do not impact\n# the relative probabilities of choosing other alternatives. For example, if IIA is valid, how I\n# choose between watching a movie or attending a football game is independent of whoever\n# is giving a concert that day. Violation of the IIA assumption complicates the choice model.\n# Therefore, much is gained when the IIA assumption is validated.\n# \n# \n# https://stats.stackexchange.com/questions/380656/checking-iia-assumption-mlogit-in-r-iris-data      in the comments \n# \n# In the example of the HMF-test on the help page \"hmftest {mlogit}\" the variable avinc is dropped because it is not varying across alternatives. None of our variables are varying over alternatives so I fear you cannot use the test. In the Econometrica paper by Hausmann and McFadden where they formulate the test they also assume constant coefficients across alternatives (which assumes that covariates are varying across alternatives)\n\n#assumption failed. However, this may not be a big deal. Simply because none of our variables are varying over alternatives. \n\n# Is it okay just to show a graph of the log-odds in the multinomial versus the logistic regressions? The log-odds do appear to change particularly for the versicolor.\n# \n# par(mfrow=c(1,2))\n# \n# mod_redu2<-multinom(op_dose ~ voriconazole + Recipient.s.Gender. + age_code, data = data)\n# lo_1.5 <-log(mod_redu2$fitted.values[,2]/(mod_redu2$fitted.values[,1]))\n# lo_high<-log(mod_redu2$fitted.values[,3]/(mod_redu2$fitted.values[,1]))\n# \n# dataless<-data[which(data$op_dose==\"less than or equal 1.5\"|data$op_dose==\"from 1.51 to 2\"),]\n# mod<-glm(op_dose ~ voriconazole + Recipient.s.Gender. + age_code,family=binomial(link=logit),data=dataless)\n# plot(lo_1.5[-seq(91:119)],predict(mod))\n# abline(a=0,b=1)\n# \n# datahigh<-data[which(data$op_dose==\"less than or equal 1.5\"|data$op_dose==\"more than 2\"),]\n# mod<-glm(op_dose ~ voriconazole + Recipient.s.Gender. + age_code, family=binomial(link=logit),data = datahigh)\n# plot(lo_high,predict(mod))\n# abline(a=0,b=1)\n\n# I am confused \n\n\n# http://www.talkstats.com/threads/multinomial-logistic-regression-testing-assumptions.65580/\n\n# For the MLR estimates to be unbiased (well, to some extent, of course :)), two assumptions must be in place -- (a) lack of multicollinearity, and (b) independence of irrelevant alternatives (IIA) (Starkweather, J., & Moske, A. K. (2011). Multinomial logistic regression). \n\n#I don't have continuous predictors, so I think multi-colinearity is not a problem\n\n\n# Multinomial logistic regression prediction table \n# \n# This can be added to the appendix to show that the middle dose range was not recommended in any of the scenarios. \n# \n# Table shows the predicted probabilities of reaching the desired plasma level under each dose with respect to age, gender and antifungal prescribed. The probability is presented as a percentage for ease of interpretation. \n\n# data$Recipient.s.Gender. <- dplyr::recode(data$Recipient.s.Gender., \"Female\" = \"0\", \"Male\" = \"1\")\n# \n# data$Recipient.s.Gender. <- as.factor(as.numeric((data$Recipient.s.Gender.)))\n\n\n# newdat <- data.frame(\n#   Recipient.s.Gender. = as.factor(rep(levels(data$Recipient.s.Gender.),  each =  4)),\n#   voriconazole = as.factor(rep(levels(as.factor(data$voriconazole)),   4)),\n#   age_bin = as.factor(rep(levels(as.factor(data$age_bin))\n#                                   , each =  4)))\n\n# newdat <- expand.grid(rec_gender=c(\"Female\",\"Male\"), \n#             voriconazole =c(\"Voriconazole\",\"No voriconazole\"), \n#             age_bin=c(\"<= 9\",\">9\"))\n\n\n# test_4_pred <- multinom(op_dose ~ voriconazole + rec_gender + age_bin , data = data)\n# \n# pred_table <- cbind(newdat, predict(test_4_pred, newdat, type = \"probs\"))\n# \n# names(pred_table) <- c(\"Gender\", \"voriconazole\", \"Age\", \"prob_Less_equal_1.5\", \"prob1.5_to_2.5\", \"prob_greater_equal_2.5\")\n# \n# pred_table$Gender <- fct_collapse(pred_table$Gender, \n#                                   \"Female\" = \"0\", \n#                                   \"Male\" = \"1\")\n\n# pred_table$recommended_dose <- ifelse(pred_table$probability_to_reach_level_at_dose_more_than_1.5 > 0.5, \">1.5\", \"<=1.5\")\n\n# I used to have the code below when there was three categories for optimum dose \n\n# cole <- pred_table %>%\n#   dplyr::select(prob_Less_equal_1.5 : prob_greater_equal_2.5)\n# \n# pred_table$recommended_dose <- colnames(cole)[max.col(cole,ties.method=\"first\")]\n# \n# pred_table <- pred_table %>%\n#   rowwise() %>%\n#   mutate(expected_percentage_of_reaching_op_dose = max(prob_Less_equal_1.5, prob1.5_to_2.5, prob_greater_equal_2.5))\n# \n# library(scales)\n# \n# pred_table <- pred_table %>%\n#   mutate(prob_Less_equal_1.5 = percent(prob_Less_equal_1.5),\n#          prob1.5_to_2.5 = percent(prob1.5_to_2.5),\n#          prob_greater_equal_2.5 = percent(prob_greater_equal_2.5),\n#        expected_percentage_of_reaching_op_dose = percent(expected_percentage_of_reaching_op_dose))\n# \n# names(pred_table) <- c(\"Gender\",\t\"voriconazole\",\t\"Age\",\t\"<=1.5\",\t\"1.5-2.5\", \t\">=2.5\",\t\"recommended_dose\", \t\"Accuracy (%)\")\n# \n# rmdtbl(pred_table)\n\n# library(lazyeval)\n# nm1 <- names(iris)[1:4]\n# iris %>%\n#   dplyr::select(Sepal.Length : Petal.Width) %>% \n#   mutate_(mak= interp(~pmin(v1), v1= as.name(nm1)))\n# \n# \n# \n# \n# DF <- data.frame(V1=c(2,8,1),V2=c(7,3,5),V3=c(9,6,4))\n# \n# colnames(DF)[apply(DF,1,which.max)]\n# \n\n# Table predicted probabilities of reaching optimum plasma level of ciclosporin\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:42.388993Z","iopub.execute_input":"2023-02-05T06:45:42.391569Z","iopub.status.idle":"2023-02-05T06:45:42.41479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Binary logistic regression ","metadata":{}},{"cell_type":"code","source":"# mod_bin_log <- glm(dose_2_lvl ~ voriconazole + rec_gender + age_bin + phenytoin + wt..D.2, data, family = binomial)\n\n# tbl_regression(mod_bin_log, exponentiate = TRUE)","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:43.275167Z","iopub.execute_input":"2023-02-05T06:45:43.277212Z","iopub.status.idle":"2023-02-05T06:45:43.291313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see the predicted probability ","metadata":{}},{"cell_type":"code","source":"# newdat_binary <- expand.grid(rec_gender=c(\"Female\",\"Male\"), \n#             voriconazole =c(\"Voriconazole\",\"No voriconazole\"), \n#             age_bin=c(\"<= 9\",\">9\"))\n\n# mod_bin_log_imited <- glm(dose_2_lvl ~ voriconazole + rec_gender + age_bin  , data, family = binomial)\n\n\n# pred_table_binary <- cbind(newdat_binary, predict(mod_bin_log_imited, newdat_binary, type = \"response\"))\n\n# names(pred_table_binary) <- c(\"Gender\", \"voriconazole\", \"Age\", \"prob_needs_higher_dose\")\n\n# pred_table_binary <- pred_table_binary %>% \n#   mutate(recommended_dose = ifelse(prob_needs_higher_dose > 0.5, \"higher than 1.5\", \"1.5\" ), \n#          probabity_reaching_level_at_selected_dose =\n#            ifelse(prob_needs_higher_dose > 0.5, scales::percent(prob_needs_higher_dose), scales::percent(1 - prob_needs_higher_dose))) %>% \n#   dplyr::select(-prob_needs_higher_dose)\n\n# rmdtbl(pred_table_binary)","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:54.697539Z","iopub.execute_input":"2023-02-05T06:45:54.70042Z","iopub.status.idle":"2023-02-05T06:45:54.718827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Ordinal logistic regression ","metadata":{}},{"cell_type":"code","source":"# Multinomial and Ordinal Logistic Regression In R\n# https://www.analyticsvidhya.com/blog/2016/02/multinomial-ordinal-logistic-regression/\n\n# require(foreign)\n# require(ggplot2)\n# require(MASS)\n# require(Hmisc)\n# require(reshape2)\n# \n# m_ord_log <- polr(op_dose ~ voriconazole + rec_gender + age_bin  + wt..D.2, data = data, Hess=TRUE)\n# \n# summary(m_ord_log)\n# # Hess=TRUE to let the model output show the observed information matrix from optimization which is used to get standard errors.\n# \n# tidy_polr <- tidy(m_ord_log, exponentiate = T, p.values = T, conf.int = T, digits = 3)\n# \n# tidy_olr <- tidy_polr %>% \n#   dplyr::select(term, 'OR' = estimate, 'lower_conf' = conf.low, 'upper_conf' = conf.high, \"P_value\" = p.value) %>%\n#   mutate_if(is.numeric, round, digits = 3) %>% \n#   filter(row_number() <= n()-2)\n# \n# tidy_olr$term <- c(\"Vori vs No Vori\", \"Male vs Female\", \"Age > 9 vs Age < 9\", \"Weight\")\n# \n# rmdtbl(tidy_olr)\n# \n# augment(m_ord_log)\n# \n# data$op_dose_coded <- fct_collapse(data$op_dose, \n#                                    '1' = '<= 1.5', \n#                                    '2' = '1.5-2.5',\n#                                    '3' = '>= 2.5') %>% \n#   as.numeric()\n# \n# sf <- function(y) {\n#   c('Y>=1' = qlogis(mean(y >= 1)),\n#     'Y>=2' = qlogis(mean(y >= 2)),\n#     'Y>=3' = qlogis(mean(y >= 3)))\n# }\n# \n# (s <- with(data, summary(as.numeric(op_dose_coded) ~ voriconazole + rec_gender + age_bin, fun=sf)))\n# # I didn't add weight to the test, as it is a continuous variable. It gives infinity in the distance\n# \n# s[, 4] <- s[, 4] - s[, 3]\n# s[, 3] <- s[, 3] - s[, 3]\n# s\n# \n# plot(s, which=1:3, pch=1:3, xlab='logit', main=' ', xlim=range(s[,3:4]))\n# \n# The model seems ok for all predictors. However, a large deviation occurs for age. \n# \n# glance(m_ord_log)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T06:45:56.027706Z","iopub.execute_input":"2023-02-05T06:45:56.029263Z","iopub.status.idle":"2023-02-05T06:45:56.044824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Survival\n\n> ## kaplan meier curve ","metadata":{}},{"cell_type":"markdown","source":"\nkm <- function(fu, st, gp, data){\n  \n  fit <- do.call(survfit, list(formula = Surv(fu, st) ~ gp ,data = data))\n \nplot = ggsurvplot(\n  fit, data = data,\n   data used to fit survival curves.\n  surv_plot(OS_data, OS_data$OS_FU, OS_data$OS_status)\n  risk.table = TRUE,       # show risk table.\n  palette = \"jco\",\n  pval = TRUE,             # show p-value of log-rank test.\n  conf.int = FALSE,         # show confidence intervals for\n<!--   # point estimaes of survival curves. -->\n  xlim = c(0,80),        # present narrower X axis, but not affect\n<!--   # survival estimates. -->\n  break.time.by = 5,     # break X axis in time intervals by 500.\n  ggtheme = theme_minimal(), # customize plot and risk table with a theme.\n  risk.table.y.text.col = T, # colour risk table text annotations.\n  risk.table.y.text = FALSE # show bars instead of names in text annotations\n<!--   # in legend of risk table -->\n)\nreturn(plot)\n}\n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T03:59:32.208959Z","iopub.execute_input":"2023-02-05T03:59:32.21048Z","iopub.status.idle":"2023-02-05T03:59:32.248434Z"}}},{"cell_type":"markdown","source":"> ## multivariate cox regression ","metadata":{}},{"cell_type":"markdown","source":"\nos_cox_mult <- coxph(Surv(os_time, os_st) ~ age_category + B.symptoms + early_advanced_stage + Result.of.Second.PET.CT, data) \n\n\ntbl_regression(os_cox_mult, exponentiate = TRUE,  pvalue_fun = function(x) style_pvalue(x, digits = 2)) %>% bold_labels() %>% italicize_levels() %>% bold_p() %>% add_n() %>% gtsummary::as_flex_table() \n","metadata":{"execution":{"iopub.status.busy":"2023-02-05T04:03:10.379198Z","iopub.execute_input":"2023-02-05T04:03:10.380868Z","iopub.status.idle":"2023-02-05T04:03:10.395603Z"}}},{"cell_type":"markdown","source":"> ## mutlivariate cox using more than 1 time dependent covariate","metadata":{}},{"cell_type":"markdown","source":"\ndata %<>% mutate(tpet=if_else(!is.na(data$time_to_sec_pet),time_to_sec_pet ,max(os_time) +1 ))\n\ndata %<>% mutate(trad=if_else(!is.na(data$rad_time) ,\n                              rad_time, max(os_time) + 1 ))\n\n\nt_pet_rad <- coxph(Surv(os_time,os_st) ~ B.symptoms + early_advanced_stage + tt(tpet) + tt(trad), data=data,\n             tt=function(x,t,...) (t>=x))\n\nvar_label(data) <- list(\n  trad = \"Radiotherapy(tdc)\",\n  tpet = \"PET CT (tdc)\"\n)\n\nt_pet_rad %>% \ngtsummary::tbl_regression(exp = TRUE)  %>% bold_labels() %>% italicize_levels()  %>%\n  modify_table_body(dplyr::select, -p.value) %>% \n  gtsummary::as_flex_table() \n","metadata":{}},{"cell_type":"markdown","source":"> ## Model diagnostics \n\nFirstly, I will the proportional hazard assumption using the schoenfeld test. I will use both the graphical and numerical tests. \n\ntest.ph <- cox.zph(os_cox_mult)\ntest.ph\n\nsignificant p values mean proportional hazard assumption violation \n\nIt’s possible to do a graphical diagnostic using the function ggcoxzph() [in the survminer package], which produces, for each covariate, graphs of the scaled Schoenfeld residuals against the transformed time.\n\nggcoxzph(test.ph)\n\nIf we see a systematic departure from the horizontal line, then we can assume proportional hazards.  \n\n\n### testing influential points \n\n\nggcoxdiagnostics(t_pet_rad, type = \"dfbeta\",\n                 linear.predictions = FALSE, ggtheme = theme_bw())\n\nAdding the type as dfbeta plots the estimated changes in the regression coefficients upon deleting each observation in turn. \n\n\nLet's also check the deviance residuals. Residuals should be roughly symmetrically distributed about zero with a standard deviation of 1.\n\nPositive values correspond to individuals that “died too soon” compared to expected survival times.\nNegative values correspond to individual that “lived too long”.\nVery large or small values are outliers, which are poorly predicted by the model.\n\n\nggcoxdiagnostics(t_pet_rad, type = \"deviance\",\n                 linear.predictions = FALSE, ggtheme = theme_bw())","metadata":{}},{"cell_type":"markdown","source":"> ## max combo test\n\n### Max combo test \n\n[maxcombo: The Group Sequential Max-Combo Test for Comparing Survival Curves](https://cran.r-project.org/web/packages/maxcombo/maxcombo.pdf) \n\nThe max-combo test is faacea generalization of the weighted log-rank test, which itself is a generalization of the logrank test. \n\nThe original paper: [Group sequential monitoring based on the maximum of weighted log-rank statistics with the Fleming-Harrington class of weights in oncology clinical trials - PubMed](https://pubmed.ncbi.nlm.nih.gov/32522077/) \n\n[A recent clinical trial that mentions maxcombo](https://clinicaltrials.gov/ProvidedDocs/27/NCT04421027/SAP_001.pdf_)\n\n\n```{r}\nmax_combo <- function(risk, overall = TRUE){\n  \n  if (overall == TRUE){\n  logrank.maxtest(\n      time  = data$os_time,\n      event = data$os_st,\n      group = risk,\n      rho   = c(0, 0, 1, 1),\n      gamma = c(0, 1, 0, 1)\n  )  \n  } else {\n    logrank.maxtest(\n      time  = data$efs_time,\n      event = data$efs_st,\n      group = risk,\n      rho   = c(0, 0, 1, 1),\n      gamma = c(0, 1, 0, 1)\n  )  \n    \n  }\n}\n\n```","metadata":{}},{"cell_type":"markdown","source":"> ## Weighted cox proportional hazard model","metadata":{}},{"cell_type":"code","source":"# # the package coxphw will not work ... because there is something wrong about specification of the time dependent covariate. Moreover, the weights can be adjusted in normal cox\n# # \n# # zero3$GVHD\n# # zero2$GVHD  \n# data$GVHD <- as.character(data$GVHD)\n# data$GVHD[data$GVHD == \"Yes\"] <- 1\n# data$GVHD[data$GVHD == \"No\"] <- 0\n\n# # data$hundred <- as.Date(data$Date.of.Stem.Cell.Infusion.) + 100\n\n# # data$GVHD.D. <- ymd(data$Date.of.Stem.Cell.Infusion.) + data$GVHD.D.\n# #data$gvhd_tdc <- ifelse(is.na(data$GVHD.D.), data$hundred, data$GVHD.D.)\n\n# # data$gvhd_tdc <- data$hundred\n# # \n# # data$gvhd_tdc[!is.na(data$GVHD.D.)] <- data$GVHD.D.[!is.na(data$GVHD.D.)]\n# # \n# # data$gvhd_tdc <- as.Date(data$gvhd_tdc)\n\n# data$GVHD.D.[is.na(data$GVHD.D.)] <- 100\n\n# n_data <- data %>% dplyr::select(\"Recipient.s.MRN.\",\"GVHD\",\"GVHD.D.\", \"rec_gender\")\n\n# colnames(n_data) <- c(\"id\", \"status\", \"time\", \"gender\")\n\n\n# long_data <- gather(data, key = week, value = level, CSA.mean.level.1: CSA3)\n\n# colnames(long_data)[1] <- \"id\"\n\n# long_data$week <- car::recode(long_data$week, \"'CSA.mean.level.1' = 7; 'CSA.2' = 14; 'CSA3' = 21 \")\n\n# # long_data$weight <- rep(1, nrow(long_data))\n# # \n# # long_data$weight[long_data$week == 7 & long_data$GVHD.D. <= 10 | (long_data$week == 14 & long_data$GVHD.D. <= 18 & long_data$GVHD.D. > 10) | (long_data$week == 21 & long_data$GVHD.D. <= 25 & long_data$GVHD.D. > 18)] <- 700/18\n# # \n# # long_data$weight[long_data$weight == 1.000] <- 300/(357-18)\n# # \n# library(lubridate)\n\n# long_data$level[long_data$level == 0] <- NA\n# # according to the vignette, missing values will be carried forward ... This is a huge problem \n\n# temp <- n_data # baseline\n   \n# pbc2 <- tmerge(temp, temp, id=id, death = event(time, status)) #set range\n# pbc2 <- tmerge(pbc2, long_data, id=id, cyclo = tdc(week, level), options = list(na.rm=TRUE))\n\n\n# pbc2$weight <- rep(1, nrow(pbc2))\n\n# see <- filter(pbc2, pbc2$time - pbc2$tstart < 8 & pbc2$time - pbc2$tstart > 0) \n\n# # I multiplied 343 ( actual number after removal of deletions ) by 0.7 .. I got 240\n# # then I divided the 240 among the 13 observations that met the criteria \n\n# pbc2$weight[pbc2$time - pbc2$tstart < 8 & pbc2$time - pbc2$tstart > 0] <- 240/13\n\n# # here I divided the remaining 30%  (0.3*343) on the remaining observations  (343-13)\n\n# pbc2$weight[pbc2$weight == 1.00] <- 103/(343-13)\n\n# #sum(pbc2$weight)  # the sum should be 343, however it is here 380 because missing data are not yet deleted\n\n# # pbc2 <- pbc2[complete.cases(pbc2$cyclo),]\n# # \n# # sum(pbc2$weight)  # here it is after removal of cases\n\n# #pbc2 <- pbc2[pbc2$cyclo != 0, ]\n\n# fit1 <- coxph(Surv(time, status==1) ~ gender ,  temp)\n\n# fit2 <- coxph(Surv(tstart, tstop, death==1) ~ gender + cyclo, weights = weight,\n#               pbc2)\n\n# fit3 <- coxph(Surv(tstart, tstop, death==1) ~ gender + log(cyclo), weights = weight,\n#               pbc2)\n# seee <- pbc2[pbc2$cyclo == 0, ]\n# #rbind('baseline fit' = coef(fit1),\n#  #     'time dependent' = coef(fit2))\n\n# coxtbl <- tidy(fit3, exponentiate = TRUE, conf.int = T)\n\n# coxtbl <- coxtbl %>% \n#   dplyr::select(term, estimate, p.value, conf.low, conf.high)\n\n# names(coxtbl) <- c(\"Risk factor\", \"HR\",\"p_value\", \"Lower CI\", \"Higher CI\")\n# rmdtbl(coxtbl)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model selection using AIC and BIC \n\n\nI will perform backward elimination and I will consider removing some variables while checking AIC and BIC. \n\n\nrmdtable( glance(t_pet_rad_efs) %>% \n  dplyr::select(AIC, BIC))\n\nLet's compare after removing `age_category`\n\nt_pet_rad_efs_no_age <- coxph(Surv(efs_time,efs_st) ~ B.symptoms + early_advanced_stage + tt(tpet) + tt(trad), data=data,\n             tt=function(x,t,...) (t>=x))\n\nrmdtable( glance(t_pet_rad_efs_no_age) %>% \n  dplyr::select(AIC, BIC))\n","metadata":{}},{"cell_type":"markdown","source":"# survey analysis ","metadata":{}},{"cell_type":"markdown","source":"## multiple response questions","metadata":{}},{"cell_type":"markdown","source":"packages \nuserfriendlyscience","metadata":{}},{"cell_type":"code","source":"# mresp <- function(gpvar, normal_var){\n#   df1 <- data %>% \n#   dplyr::select(Type.of.dental.practice...Multiple.responses.enabled., !!gpvar) %>% cSplit_e('Type.of.dental.practice...Multiple.responses.enabled.', ',', type= 'character', fill=0, drop=T)\n# names(df1) <-  sub('.*_', '', names(df1))\n\n# df2 <- data.frame(cross.multi.table(df1[,names(df1)[2:length(names(df1))]], \n#                   normal_var, true.codes=list(\"Y\"), freq=TRUE, tfreq=\"row\", n=F, digits = 0)) \n# df2 <- df2 %>% \n#   rownames_to_column() %>% \n#   rename(\"Dental practice\" = rowname)\n# return(df2)\n# }\n\n# cong_hrt <-  mresp(quo(How.regularly.do.you.encounter.a.child.with.Congenital..Rheumatic.Heart.Disease.in.your.practice.), data$How.regularly.do.you.encounter.a.child.with.Congenital..Rheumatic.Heart.Disease.in.your.practice.)\n\n\n# mresp_gnrl <- function(mrv, gpvar, normal_var){ # same function but for different multile response variables\n#   df1 <- data %>% \n#   dplyr::select(!!mrv, !!gpvar) %>% cSplit_e(1, ',', type= 'character', fill=0, drop=T)\n# names(df1) <-  sub('.*_', '', names(df1))\n\n# df2 <- data.frame(cross.multi.table(df1[,names(df1)[2:length(names(df1))]], \n#                   normal_var, true.codes=list(\"Y\"), freq=T, tfreq=\"row\", n=T, digits = 0)) \n# df2 <- df2 %>% \n#   rownames_to_column()\n  \n# return(df2)\n# }\n\n# mresp_total<- function(gpvar, normal_var){  # this function is used only to get the total of each option in the mult resp column \n#   df1 <- data %>% \n#   dplyr::select(Type.of.dental.practice...Multiple.responses.enabled., !!gpvar) %>% cSplit_e('Type.of.dental.practice...Multiple.responses.enabled.', ',', type= 'character', fill=0, drop=T)\n# names(df1) <-  sub('.*_', '', names(df1))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Item response theory \n\nhttps://github.com/santarabantoosoo/survey_irrational-beliefs\n\nneeds update ","metadata":{}},{"cell_type":"markdown","source":"# TO DO \n> update projects on github with dummy data \n> use rmarkdown here ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}